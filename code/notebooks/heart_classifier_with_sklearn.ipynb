{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import json\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Scikit-Learn Classifer\n",
    "\n",
    "### API required to become an estimator\n",
    "\n",
    "- Class should provide:\n",
    "  - a `fit()`\n",
    "    - Given data (features) and target, fits the model to make predictions based on given data\n",
    "  - a `predict()`\n",
    "    - Given data (features), returns array of predictions for each observation based on test data in `fit()`\n",
    "  - a `constructor` (`__init__()`)\n",
    "    - Can supply default arguments here and does any initialization required\n",
    "  \n",
    "- Can provide other useful methods like:\n",
    " - `predict_proba()`\n",
    " - `score()`\n",
    "\n",
    "For more information, go to [scikit-learn's website](https://scikit-learn.org/stable/developers/develop.html#apis-of-scikit-learn-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels, check_classification_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/ronitf/heart-disease-uci?select=heart.csv\n",
    "\n",
    "heart_disease = pd.read_csv(\"../../datasets/heart.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "heart_disease = heart_disease.rename(columns={'target': 'disease_present'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "target_col = 'disease_present'\n",
    "# Remove quantitative variables -- for now\n",
    "other_to_drop = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "t = heart_disease['disease_present']\n",
    "X2 = heart_disease.drop(columns=([target_col] + other_to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our `CustomDecisionTreeClassifier` class\n",
    "\n",
    "Our custom decision tree classifier, which we implemented [here](https://csc466-team7.github.io/csc466_project/#/example/1), needs to be turned into a class. From there, we will add required sklearn estimator checks so that the `check_estimator()` function passes when given our model. This means sklearn has deemed our estimator correct in terms of having the necessary functionality and basic checks to use it as a classifier.\n",
    "\n",
    "Let's get started by making a class that extends `BaseEstimator` and `ClassifierMixin`, which both provide some helpful functions.\n",
    "\n",
    "```python\n",
    "class CustomDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, criterion='entropy',default=None):\n",
    "        self.criterion = criterion\n",
    "        self.default = default\n",
    "        \n",
    "    # Needed for check_estimator\n",
    "    def _more_tags(self):\n",
    "        return {\n",
    "            \"poor_score\": True\n",
    "        }\n",
    "```\n",
    "\n",
    "We have only written an `entropy` function previously, but if we wanted to have other ways of determining information gain, we could specify it with the `criterion` attribute, as the `DecisionTreeClassifier` sklearn provides does.\n",
    "\n",
    "We also provide a `default` value for which the user can give to put as the default prediction to use if we make it to a point where the features given create a circumstance where no branch in the decision tree exists.\n",
    "\n",
    "The `_more_tags()` method is provided here with a return dictionary of `poor_score = True` to let sklearn know that our decision tree may be a poor predictor and that's ok. This is because our decision tree is not effective for quanititative data that sklearn may pass as tests for our classifier. We can make a classifier that does handle continuous variables, though. We have not done that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "quiz"
    ]
   },
   "source": [
    "<qinline>\n",
    "    \n",
    "<question>\n",
    "    \n",
    "Why would we want to provide an optional default? Why not just have the classifier choose what seems best for us? What could a problem be if the user chooses a default, though?\n",
    "    \n",
    "</question>\n",
    "    \n",
    "<answer>\n",
    "    \n",
    "The user may tune their `default` during hyperparameterizing optimization (model tuning) to choose the seemingly best default. They also may know which default should be best under certain cases for training.\n",
    "\n",
    "This could lead, though, to overfitting if the user isn't careful.\n",
    "    \n",
    "</answer>\n",
    "    \n",
    "</qinline>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing fit/predict\n",
    "\n",
    "So what changes here?\n",
    "\n",
    "Well, `fit()` will do some of the transformations and checks required and then will call our `tree_creation` function to train our classifier from the given training data and `make_rules` to be ready to make predicitions from.\n",
    "\n",
    "The `predict()` will also do some transformations and checks and then will call our `make_predictions` function on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The hard part\n",
    "\n",
    "Now here might be some hard news.\n",
    "\n",
    "*We are not guaranteed to be passed a **pandas DataFrame** as the X (training set) variable to fit or predict*.\n",
    "\n",
    "We will assume that we do get at least a 2D matrix that corresponds to a dataframe, though, and a 1D matrix that corresponds to the targets for each observation. This means we cannot rely on `X.columns` to get the columns out of a dataframe and can really only use `numpy` functions during this OR turn it into a `pandas` dataframe ourselves. For this exercise, we used `numpy` functions.\n",
    "\n",
    "Luckily, sklearn does provide some functions we can use during `fit()` and `predict()` to help do some checks and shaping for us:\n",
    "\n",
    "- `fit()`\n",
    "  - `check_X_y(X, y)` - Given `X` and `y`, returns a numpy array for each instead, even if input is `pandas DataFrame` or `Series`\n",
    "  - `check_classification_targets(y)` - Makes sure values in given `y` lead to a classification problem\n",
    "  - `np.atleast_2d(X)` and `np.atleast_1d(y)` - checks and coerces given matrix to dimension specified\n",
    "- `predict()`\n",
    "  - `check_is_fitted(self)` - makes sure model has been `fit()`\n",
    "  - `check_array(X)` - From sklearn: \"By default, the input is checked to be a non-empty 2D array containing only finite values\"\n",
    "  \n",
    "### But what if we used DataFrame `columns` to pick certain columns or generate rules?\n",
    "\n",
    "All is not lost! One way to go about this is to convert the `numpy` arrays to a DataFrame with named columns of your own. This is the easy lame way :D.\n",
    "\n",
    "\n",
    "Another way is to just keep track of the current indexes of the columns you still have during tree creation. Thus, the starting indexes to `generate_tree` would be\n",
    "```python\n",
    "np.asarray(list(range(self.n_features_in_)))\n",
    "```\n",
    "where `self.n_features_in_ = X.shape[1]`. This is because we start with all indexes at first, which is just all the features' indexes. On subsequent calls to `generate_tree`, we can pass indexes that relate to the original indexes with all the features.\n",
    "\n",
    "Let's say we have a decision tree with features: Ethnicity, Age, and Height. Then we pick Age as our best feature (highest info gain). That means we will pass Ethnicity and Height as a new subtree to make. To start, the indexes would have been `0, 1, and 2`. The subtree would get indexes `0 and 2` then.\n",
    "  - `0 -> Ethnicity`\n",
    "  - `1 -> Age`\n",
    "  - `2 -> Height`\n",
    "  \n",
    "Thus the function definition for the `_tree_creation` in your class may look like:\n",
    "```python\n",
    "def _tree_creation(self,X,y,related_idxs):\n",
    "```\n",
    "\n",
    "and will still return a dictionary **where instead of column names you get indexes**.\n",
    "\n",
    "\n",
    "Some helpful `numpy` functions for dealing with `numpy` arrays:\n",
    "- `unique(y)` - returns only unique values. Can also return indexes and counts as well!\n",
    "- `where(condition)` - Given condition traverses array and returns indexes that satisfy condition. Helpful for subsetting based on condition. Can be used similarly to `df[z == 2]` (`np.where(z == 2)` where `z` is numpy array)\n",
    "- `delete(y, value(s), axis)` - returns new numpy array with value(s) deleted along that axis. If you have 2D matrix and want to delete a column, can do: `np.delete(X, column, axis=1)`\n",
    "- `numpy` arrays can be subsetted like `pandas Series` can be. `X[:, col]` selects all observations in the 2D matrix `X` at column `col`.\n",
    "\n",
    "\n",
    "#### The nice part about all of this is that the `generate_rules` function really doesn't have to change since the given tree is still just a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "quiz"
    ]
   },
   "source": [
    "<qinline>\n",
    "    \n",
    "<question>\n",
    "\n",
    "Does the `make_predictions` main function logic need to change? If so, how?\n",
    "\n",
    "</question>\n",
    "\n",
    "<answer>\n",
    "\n",
    "Not really! Since our make predictions just takes the rules and an observation, the `make_predictions` function can stay the same. The only thing that really needs to happen is some preprocessing that coerces the observation into a `numpy` array and checks to make sure the model has been fitted. \n",
    "\n",
    "</answer>\n",
    "    \n",
    "</qinline>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing it out with column names\n",
    "\n",
    "Since we know only have indexes in our tree, if we received a `DataFrame` with columns during fitting, we may want to also print our tree with columns. Here's a helper function to do that:\n",
    "\n",
    "```python\n",
    "    def print_decision_tree(self, with_cols=False):\n",
    "        try:\n",
    "            getattr(self, \"_tree\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before printing tree!\")\n",
    "            \n",
    "        self._print_tree_helper(self._tree, with_cols)\n",
    "            \n",
    "    def _print_tree_helper(self, tree, replace_cols):\n",
    "        mytree = copy.deepcopy(tree)\n",
    "        def fix_keys(tree):\n",
    "            if type(tree) != dict:\n",
    "                if type(tree) == np.int64:\n",
    "                    return int(tree)\n",
    "            new_tree = {}\n",
    "            for key in list(tree.keys()):\n",
    "                if type(key) == np.int64 or type(key) == np.int32:\n",
    "                    if replace_cols:\n",
    "                        new_tree[self.cols_[int(key)]] = tree[key]\n",
    "                    else:\n",
    "                        new_tree[int(key)] = tree[key]\n",
    "                else:\n",
    "                    new_tree[key] = tree[key]\n",
    "            for key in new_tree.keys():\n",
    "                new_tree[key] = fix_keys(new_tree[key])\n",
    "            return new_tree\n",
    "        mytree = fix_keys(mytree)\n",
    "        print(json.dumps(mytree, indent=4, sort_keys=True))\n",
    "```\n",
    "\n",
    "But where does `self.cols_` come from to do this? You can add a way to grab the columns in fit:\n",
    "```python\n",
    "if hasattr(X, 'columns'):\n",
    "    self.cols_ = X.columns\n",
    "else:\n",
    "    self.cols_ = None\n",
    "```\n",
    "\n",
    "then all we have to do is call the print correctly:\n",
    "```python\n",
    "model.print_decision_tree(with_cols=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class CustomDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, criterion='entropy',default=None):\n",
    "        self.criterion = criterion\n",
    "        self.default = default\n",
    "    \n",
    "    # Needed for check_estimator\n",
    "    def _more_tags(self):\n",
    "        return {\n",
    "            \"poor_score\": True\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if hasattr(X, 'columns'):\n",
    "            self.cols_ = X.columns\n",
    "        else:\n",
    "            self.cols_ = None\n",
    "        \n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        check_classification_targets(y)\n",
    "        \n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # https://github.com/scikit-learn/scikit-learn/blob/053d2d1af477d9dc17e69162b9f2298c0fda5905/sklearn/tree/_classes.py#L83\n",
    "\n",
    "        X = np.copy(X)\n",
    "        y = np.copy(y)\n",
    "\n",
    "        n_samples, self.n_features_in_ = X.shape\n",
    "        \n",
    "        X = np.atleast_2d(X)\n",
    "        y = np.atleast_1d(y)\n",
    "\n",
    "        self.n_outputs_ = 1\n",
    "\n",
    "        start_idxs = np.asarray(list(range(self.n_features_in_)))\n",
    "        self._tree = self._make_tree(X, y, start_idxs)\n",
    "        self._rules = self._get_rules(self._tree)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        if X.shape[1] != self.n_features_in_:\n",
    "            raise ValueError(\"Features in predict different than features in fit\")\n",
    "        \n",
    "        default = self.y_[0] if self.default == None else self.default\n",
    "        \n",
    "        y_vals = []\n",
    "        for x in X:\n",
    "            y_vals.append(self._make_prediction(self._rules,x,default))\n",
    "        \n",
    "        return np.asarray(y_vals)\n",
    "\n",
    "    def _get_entropy(self, y):\n",
    "        e = 0\n",
    "        for v in np.unique(y):\n",
    "            p_v = np.sum(y == v) / len(y)\n",
    "            total = -1 * (p_v * np.log2(p_v))\n",
    "            e += total\n",
    "        return e\n",
    "    \n",
    "    def _gain(self, y,x):\n",
    "        g = 0\n",
    "        for v in np.unique(x):\n",
    "            sub_t = y[np.where(x == v)]\n",
    "            g += (len(sub_t) / len(y)) * self._get_entropy(sub_t)\n",
    "        return self._get_entropy(y) - g\n",
    "        \n",
    "    \n",
    "    # use counts in case of tie\n",
    "    def _high_freq_class(self, y):\n",
    "        # https://stackoverflow.com/questions/6252280/find-the-most-frequent-number-in-a-numpy-array\n",
    "#         y_counts = np.bincount(y)\n",
    "#         y_vals = np.where(y_counts == y_counts.max())[0]\n",
    "#         numpy.argsort(vals)\n",
    "        u, c = np.unique(y, return_counts = True)\n",
    "        temp = u[c == c.max()]\n",
    "        return temp[0]\n",
    "\n",
    "    def _make_tree(self,X,y,related_idxs):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return y[0]\n",
    "\n",
    "        if X.shape[1] == 0:\n",
    "            return self._high_freq_class(y)\n",
    "\n",
    "        tree = {}\n",
    "        \n",
    "        # Find best split\n",
    "        col = None\n",
    "        gr = -1\n",
    "        for c in range(X.shape[1]):\n",
    "            cur_gain_ratio = self._gain(y, X[:, c])\n",
    "            if cur_gain_ratio > gr:\n",
    "                gr = cur_gain_ratio\n",
    "                col = c\n",
    "    \n",
    "    \n",
    "        correct_col = related_idxs[col]\n",
    "        tree[correct_col] = {}\n",
    "\n",
    "        if gr == 0:\n",
    "            return self._high_freq_class(y)\n",
    "        \n",
    "        X_col = X[:, col]\n",
    "        unique_vals = np.unique(X_col)\n",
    "\n",
    "        for v in unique_vals:\n",
    "            assert(X_col.ndim == 1)\n",
    "            indexes = np.where(X_col == v)\n",
    "            new_X = X[indexes[0], :]\n",
    "            new_X = np.delete(new_X, col, axis=1)\n",
    "            new_y = y[indexes]\n",
    "            new_valid_idxs = np.delete(related_idxs, col, axis=0)\n",
    "            tree[correct_col][str(v)] = self._make_tree(new_X,new_y,new_valid_idxs)\n",
    "\n",
    "        return tree\n",
    "    \n",
    "    def _get_rules(self, tree):\n",
    "        rules = []\n",
    "        if type(tree) != dict:\n",
    "            return [[tree]]\n",
    "        for col in tree:\n",
    "            for val in tree[col]:\n",
    "                tup = (col, val)\n",
    "                generated_sub_rules = self._get_rules(tree[col][val])\n",
    "                for sub_rule in generated_sub_rules:\n",
    "                    new_rule = [tup]\n",
    "                    new_rule.extend(sub_rule)\n",
    "                    rules.append(new_rule)\n",
    "\n",
    "        return rules\n",
    "\n",
    "    def _eq_rule(self, val_to_match):\n",
    "        def eq_matcher(x):\n",
    "            return x[0][1] == str(val_to_match)\n",
    "        \n",
    "        return eq_matcher\n",
    "\n",
    "    # Used to make a prediction given a decision tree's rule and some inputs\n",
    "    def _make_prediction(self, rules,x,default):\n",
    "        if len(rules) == 0:\n",
    "            return default\n",
    "\n",
    "        tups = []\n",
    "        next_rule = rules[0][0]\n",
    "\n",
    "        if type(next_rule) != tuple:\n",
    "            return next_rule\n",
    "\n",
    "        col = next_rule[0]\n",
    "\n",
    "        matching_value = x[col]\n",
    "        filter_rule = self._eq_rule(matching_value)\n",
    "\n",
    "        viable_rules = list(filter(filter_rule, rules))\n",
    "\n",
    "        if len(viable_rules) == 0:\n",
    "            return default\n",
    "\n",
    "        new_rules = list(map(lambda x: x[1:], viable_rules))\n",
    "\n",
    "        return self._make_prediction(new_rules, x, default)\n",
    "    \n",
    "    def print_decision_tree(self, with_cols=False):\n",
    "        try:\n",
    "            getattr(self, \"_tree\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before printing tree!\")\n",
    "            \n",
    "        CustomDecisionTreeClassifier._print_tree_helper(self._tree, with_cols, self.cols_)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _print_tree_helper(tree, replace_cols, cols = None):\n",
    "        mytree = copy.deepcopy(tree)\n",
    "        def fix_keys(tree):\n",
    "            if type(tree) != dict:\n",
    "                if type(tree) == np.int64:\n",
    "                    return int(tree)\n",
    "            new_tree = {}\n",
    "            for key in list(tree.keys()):\n",
    "                if type(key) == np.int64 or type(key) == np.int32:\n",
    "                    if replace_cols:\n",
    "                        new_tree[cols[int(key)]] = tree[key]\n",
    "                    else:\n",
    "                        new_tree[int(key)] = tree[key]\n",
    "                else:\n",
    "                    new_tree[key] = tree[key]\n",
    "            for key in new_tree.keys():\n",
    "                new_tree[key] = fix_keys(new_tree[key])\n",
    "            return new_tree\n",
    "        mytree = fix_keys(mytree)\n",
    "        print(json.dumps(mytree, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's check out if our estimator works with the heart dataset again. We should get the same scores!\n",
    "\n",
    "Once again we will sklearn's `train_test_split` and `accuracy_score` and `f1_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "show"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7912087912087912\n",
      "F1 score: 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "X2_train, X2_test, t_train, t_test = train_test_split(X2, t, test_size=0.3, random_state = 0)\n",
    "\n",
    "clf = CustomDecisionTreeClassifier(default=1)\n",
    "y_test = clf.fit(X2_train, t_train).predict(X2_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, t_test)}')\n",
    "print(f'F1 score: {f1_score(y_test, t_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the decision tree with the columns and indexes next to them as an example of what happens\n",
    "\n",
    "First a table of the indexes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def print_decision_tree_custom(tree_model):\n",
    "    new_cols = []\n",
    "    for i, col in enumerate(tree_model.cols_):\n",
    "        new_cols.append(f\"{col}/{i}\")\n",
    "        \n",
    "    CustomDecisionTreeClassifier._print_tree_helper(tree_model._tree, True, new_cols)\n",
    "    \n",
    "def print_index_table(tree_model):\n",
    "    return pd.DataFrame(list(range(tree_model.n_features_in_)), index=tree_model.cols_, columns=[\"Column Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Index\n",
       "sex                 0\n",
       "cp                  1\n",
       "fbs                 2\n",
       "restecg             3\n",
       "exang               4\n",
       "slope               5\n",
       "ca                  6\n",
       "thal                7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_index_table(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thal/7\": {\n",
      "        \"0\": {\n",
      "            \"sex/0\": {\n",
      "                \"0\": 1,\n",
      "                \"1\": 0\n",
      "            }\n",
      "        },\n",
      "        \"1\": {\n",
      "            \"ca/6\": {\n",
      "                \"0\": {\n",
      "                    \"restecg/3\": {\n",
      "                        \"0\": 1,\n",
      "                        \"1\": {\n",
      "                            \"slope/5\": {\n",
      "                                \"0\": 0,\n",
      "                                \"1\": 0\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"1\": 0,\n",
      "                \"2\": 0,\n",
      "                \"3\": 0\n",
      "            }\n",
      "        },\n",
      "        \"2\": {\n",
      "            \"ca/6\": {\n",
      "                \"0\": {\n",
      "                    \"restecg/3\": {\n",
      "                        \"0\": {\n",
      "                            \"cp/1\": {\n",
      "                                \"0\": {\n",
      "                                    \"slope/5\": {\n",
      "                                        \"1\": 1,\n",
      "                                        \"2\": {\n",
      "                                            \"sex/0\": {\n",
      "                                                \"0\": 1,\n",
      "                                                \"1\": 1\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"1\": {\n",
      "                                    \"sex/0\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"slope/5\": {\n",
      "                                                \"1\": 0,\n",
      "                                                \"2\": 1\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"2\": 1,\n",
      "                                \"3\": {\n",
      "                                    \"sex/0\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"exang/4\": {\n",
      "                                                \"0\": 0,\n",
      "                                                \"1\": 1\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                }\n",
      "                            }\n",
      "                        },\n",
      "                        \"1\": {\n",
      "                            \"cp/1\": {\n",
      "                                \"0\": {\n",
      "                                    \"exang/4\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"slope/5\": {\n",
      "                                                \"1\": 0,\n",
      "                                                \"2\": 1\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"1\": 1,\n",
      "                                \"2\": {\n",
      "                                    \"sex/0\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"exang/4\": {\n",
      "                                                \"0\": {\n",
      "                                                    \"slope/5\": {\n",
      "                                                        \"0\": 1,\n",
      "                                                        \"1\": 0,\n",
      "                                                        \"2\": 1\n",
      "                                                    }\n",
      "                                                },\n",
      "                                                \"1\": 1\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"3\": 1\n",
      "                            }\n",
      "                        },\n",
      "                        \"2\": {\n",
      "                            \"cp/1\": {\n",
      "                                \"0\": 0,\n",
      "                                \"2\": 1\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"1\": {\n",
      "                    \"cp/1\": {\n",
      "                        \"0\": 0,\n",
      "                        \"1\": 1,\n",
      "                        \"2\": 1,\n",
      "                        \"3\": 0\n",
      "                    }\n",
      "                },\n",
      "                \"2\": {\n",
      "                    \"exang/4\": {\n",
      "                        \"0\": {\n",
      "                            \"fbs/2\": {\n",
      "                                \"0\": {\n",
      "                                    \"sex/0\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"restecg/3\": {\n",
      "                                                \"0\": 1,\n",
      "                                                \"1\": 0\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"1\": 0\n",
      "                            }\n",
      "                        },\n",
      "                        \"1\": 0\n",
      "                    }\n",
      "                },\n",
      "                \"3\": {\n",
      "                    \"cp/1\": {\n",
      "                        \"0\": 0,\n",
      "                        \"2\": {\n",
      "                            \"fbs/2\": {\n",
      "                                \"0\": 0,\n",
      "                                \"1\": 1\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"4\": 1\n",
      "            }\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"cp/1\": {\n",
      "                \"0\": {\n",
      "                    \"ca/6\": {\n",
      "                        \"0\": {\n",
      "                            \"slope/5\": {\n",
      "                                \"0\": 0,\n",
      "                                \"1\": 0,\n",
      "                                \"2\": {\n",
      "                                    \"restecg/3\": {\n",
      "                                        \"0\": {\n",
      "                                            \"exang/4\": {\n",
      "                                                \"0\": 0,\n",
      "                                                \"1\": 0\n",
      "                                            }\n",
      "                                        },\n",
      "                                        \"1\": {\n",
      "                                            \"exang/4\": {\n",
      "                                                \"0\": 1,\n",
      "                                                \"1\": 0\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                }\n",
      "                            }\n",
      "                        },\n",
      "                        \"1\": {\n",
      "                            \"slope/5\": {\n",
      "                                \"1\": {\n",
      "                                    \"restecg/3\": {\n",
      "                                        \"0\": 0,\n",
      "                                        \"1\": {\n",
      "                                            \"exang/4\": {\n",
      "                                                \"0\": 0,\n",
      "                                                \"1\": 0\n",
      "                                            }\n",
      "                                        },\n",
      "                                        \"2\": 0\n",
      "                                    }\n",
      "                                },\n",
      "                                \"2\": 0\n",
      "                            }\n",
      "                        },\n",
      "                        \"2\": 0,\n",
      "                        \"3\": 0,\n",
      "                        \"4\": 0\n",
      "                    }\n",
      "                },\n",
      "                \"1\": {\n",
      "                    \"slope/5\": {\n",
      "                        \"0\": 0,\n",
      "                        \"1\": 1,\n",
      "                        \"2\": {\n",
      "                            \"fbs/2\": {\n",
      "                                \"0\": {\n",
      "                                    \"restecg/3\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": 0\n",
      "                                    }\n",
      "                                },\n",
      "                                \"1\": 1\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"2\": {\n",
      "                    \"slope/5\": {\n",
      "                        \"1\": {\n",
      "                            \"ca/6\": {\n",
      "                                \"0\": {\n",
      "                                    \"exang/4\": {\n",
      "                                        \"0\": 1,\n",
      "                                        \"1\": {\n",
      "                                            \"fbs/2\": {\n",
      "                                                \"0\": {\n",
      "                                                    \"restecg/3\": {\n",
      "                                                        \"0\": 1,\n",
      "                                                        \"1\": 0\n",
      "                                                    }\n",
      "                                                },\n",
      "                                                \"1\": 0\n",
      "                                            }\n",
      "                                        }\n",
      "                                    }\n",
      "                                },\n",
      "                                \"1\": 0,\n",
      "                                \"3\": 0\n",
      "                            }\n",
      "                        },\n",
      "                        \"2\": 1\n",
      "                    }\n",
      "                },\n",
      "                \"3\": {\n",
      "                    \"fbs/2\": {\n",
      "                        \"0\": {\n",
      "                            \"restecg/3\": {\n",
      "                                \"0\": 1,\n",
      "                                \"1\": {\n",
      "                                    \"slope/5\": {\n",
      "                                        \"1\": 0,\n",
      "                                        \"2\": 1\n",
      "                                    }\n",
      "                                }\n",
      "                            }\n",
      "                        },\n",
      "                        \"1\": 1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_custom(clf.fit(X2_train, t_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `thal`, which is columns number 7, is the most important feature according to our deicison tree. If `thal` is 0, then `sex`, column number 0, is our next most important feature for the subtree. The actual tree that gets produced, if just using indexes, will just have a `7` instead of `thal` if the column names are not replaced. This is just a visualization of how the conversion can be done eaisly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! If you remember the implementation guide for ID3 classifier, those scores are **exactly the same** as what sklearn's `DecisionTreeClassifier` gives back!\n",
    "\n",
    "### Alright, final check! Let's see if our custom classifier passes as a classifier according to sklearn!\n",
    "\n",
    "Run `check_estimator` with an instantiation. **_No output is good output!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "show"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135039273248 0.7151893663724195 0.6027633760716439\n",
      " 0.5448831829968969 0.4236547993389047 0.6458941130666561\n",
      " 0.4375872112626925 0.8917730007820798 0.9636627605010293\n",
      " 0.3834415188257777]\n",
      "object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "argument must be a string or number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-073e249bf44b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheck_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCustomDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\utils\\estimator_checks.py\u001b[0m in \u001b[0;36mcheck_estimator\u001b[1;34m(Estimator, generate_only)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchecks_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSkipTest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;31m# SkipTest is thrown when pandas can't be imported, or by checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\utils\\_testing.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\utils\\estimator_checks.py\u001b[0m in \u001b[0;36mcheck_dtype_object\u001b[1;34m(name, estimator_orig)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_enforce_estimator_tags_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-fefb96781879>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mCustomDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_num_str_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mCustomDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_X_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-fefb96781879>\u001b[0m in \u001b[0;36mcheck_X_dtype\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_X_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mCustomDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_num_str_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-fefb96781879>\u001b[0m in \u001b[0;36mcheck_num_str_dtype\u001b[1;34m(vec)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"argument must be a string or number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: argument must be a string or number"
     ]
    }
   ],
   "source": [
    "check_estimator(CustomDecisionTreeClassifier())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
